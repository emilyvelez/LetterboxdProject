{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e51485",
   "metadata": {},
   "source": [
    "# Sentiment Analysis \n",
    "\n",
    "Sentiment analysis is a technique used to determine the emotional tone or sentiment expressed in a text. It involves analyzing the words and phrases used in the text to identify the underlying sentiment, whether it is positive, negative, or neutral. There are different ways to do sentiment analysis, we will be focusing on a Lexicon-based approach.  \n",
    "\n",
    "### Lexicon-based Analysis \n",
    "This type of analysis involves using a set of predefined rules and heuristics to determine the sentiment of a piece of text. These rules are typically based on lexical and syntactic features of the text, such as the presence of positive or negative words and phrases. \n",
    "\n",
    "One of the main challenges in sentiment analysis is the inherent complexity of human language. Text data often contains sarcasm, irony, and other forms of figurative language that can be difficult to interpret using traditional methods. While lexicon-based analysis can be relatively simple to implement and interpret, it may not be as accurate as ML-based or transformed-based approaches, especially when dealing with complex or ambiguous text data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc19a045",
   "metadata": {},
   "source": [
    "We will be using the NLTK Python library to do our analysis which contains the modules for the Lexicon-based approach. The analysis is broken into 3-steps \n",
    "(following [DataCamp](https://www.datacamp.com/tutorial/text-analytics-beginners-nltk)):\n",
    "\n",
    "1. Importing the NLTK library and the modules for our analysis, as well as the data set\n",
    "2. Preprocessing the data: meaning preparing the data for the sentiment analysis\n",
    "3. NLTK Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829c54cd",
   "metadata": {},
   "source": [
    "### Step 1: NLTK library and data set\n",
    "\n",
    "#### 1.1 Importing NLTK library and modules\n",
    "\n",
    "Let us start by importing the NLTK library and its modules, we will explain what each module does as we go along. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6c686364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk # import the NLTK library into this notebook so we can use it \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer # import the sentiment analyzer (VADER) module from NLTK\n",
    "from nltk.corpus import stopwords # import the stop words module from NLTK \n",
    "from nltk.tokenize import TweetTokenizer # import the tokenizer module from NLTK\n",
    "from nltk.stem import WordNetLemmatizer # import the lemmatizer module from NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe7f15",
   "metadata": {},
   "source": [
    "#### 1.2 Importing the data set\n",
    "For simplicity I will not dive into the details of how the data set is imported into Python. Long story short, we use the library, Pandas, to help us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "26bf46f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Reviewer name</th>\n",
       "      <th>Clean_Review_date</th>\n",
       "      <th>Clean_Review</th>\n",
       "      <th>Clean_Comment Count</th>\n",
       "      <th>Like count</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clue</td>\n",
       "      <td>1985</td>\n",
       "      <td>Branson Reese</td>\n",
       "      <td>1996-10-16</td>\n",
       "      <td>My dad got in so much trouble for showing me t...</td>\n",
       "      <td>6</td>\n",
       "      <td>2,286 likes</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beetlejuice</td>\n",
       "      <td>1988</td>\n",
       "      <td>Branson Reese</td>\n",
       "      <td>1999-10-21</td>\n",
       "      <td>Thank GOD Tim Burton made this movie in 1988 a...</td>\n",
       "      <td>12</td>\n",
       "      <td>3,304 likes</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Being John Malkovich</td>\n",
       "      <td>1999</td>\n",
       "      <td>Than Tibbetts</td>\n",
       "      <td>2010-10-04</td>\n",
       "      <td>Malkovich. Malkovich Malkovich Malkovich, Malk...</td>\n",
       "      <td>6</td>\n",
       "      <td>4,300 likes</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Muppets</td>\n",
       "      <td>2011</td>\n",
       "      <td>Jeff</td>\n",
       "      <td>2012-03-06</td>\n",
       "      <td>It's fine if you don't like this movie, but it...</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mysterious Skin</td>\n",
       "      <td>2004</td>\n",
       "      <td>Cole</td>\n",
       "      <td>2012-03-11</td>\n",
       "      <td>This movie is beautiful, captivating, fascinat...</td>\n",
       "      <td>4</td>\n",
       "      <td>6  23 likes</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>Drive</td>\n",
       "      <td>2011</td>\n",
       "      <td>k??rsten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes, I just saw it for the first timeYes, I lo...</td>\n",
       "      <td>9</td>\n",
       "      <td>2,160 likes</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>1999</td>\n",
       "      <td>hunt??r</td>\n",
       "      <td>NaN</td>\n",
       "      <td>if I was next to brad, I would have dropped th...</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>The Bling Ring</td>\n",
       "      <td>2013</td>\n",
       "      <td>k??rsten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not a single good shot or outfit in this entir...</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>A Serbian Film</td>\n",
       "      <td>2010</td>\n",
       "      <td>DirkH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OH MY GOD, LOOK AT HOW CONTROVERSIAL I AM!!!!!!</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>CODA</td>\n",
       "      <td>2021</td>\n",
       "      <td>James (Schaffrillas)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crazy how such a cliche and predictable movie ...</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2837 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                movie_name  Release Year         Reviewer name  \\\n",
       "0                     Clue          1985         Branson Reese   \n",
       "1              Beetlejuice          1988         Branson Reese   \n",
       "2     Being John Malkovich          1999         Than Tibbetts   \n",
       "3              The Muppets          2011                  Jeff   \n",
       "4          Mysterious Skin          2004                  Cole   \n",
       "...                    ...           ...                   ...   \n",
       "2832                 Drive          2011              k??rsten   \n",
       "2833            Fight Club          1999               hunt??r   \n",
       "2834        The Bling Ring          2013              k??rsten   \n",
       "2835        A Serbian Film          2010                 DirkH   \n",
       "2836                  CODA          2021  James (Schaffrillas)   \n",
       "\n",
       "     Clean_Review_date                                       Clean_Review  \\\n",
       "0           1996-10-16  My dad got in so much trouble for showing me t...   \n",
       "1           1999-10-21  Thank GOD Tim Burton made this movie in 1988 a...   \n",
       "2           2010-10-04  Malkovich. Malkovich Malkovich Malkovich, Malk...   \n",
       "3           2012-03-06  It's fine if you don't like this movie, but it...   \n",
       "4           2012-03-11  This movie is beautiful, captivating, fascinat...   \n",
       "...                ...                                                ...   \n",
       "2832               NaN  Yes, I just saw it for the first timeYes, I lo...   \n",
       "2833               NaN  if I was next to brad, I would have dropped th...   \n",
       "2834               NaN  not a single good shot or outfit in this entir...   \n",
       "2835               NaN    OH MY GOD, LOOK AT HOW CONTROVERSIAL I AM!!!!!!   \n",
       "2836               NaN  Crazy how such a cliche and predictable movie ...   \n",
       "\n",
       "     Clean_Comment Count     Like count   genre  \n",
       "0                      6    2,286 likes  Comedy  \n",
       "1                     12    3,304 likes  Comedy  \n",
       "2                      6    4,300 likes  Comedy  \n",
       "3                     31            NaN  Comedy  \n",
       "4                      4    6  23 likes   Drama  \n",
       "...                  ...            ...     ...  \n",
       "2832                   9    2,160 likes  Action  \n",
       "2833                  19            NaN   Drama  \n",
       "2834                  30            NaN   Crime  \n",
       "2835                  65            NaN  Horror  \n",
       "2836                  32            NaN   Drama  \n",
       "\n",
       "[2837 rows x 8 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd # Import Pandas\n",
    "\n",
    "# Read our letterboxd CSV file from the google docs and store it in variable called 'data'\n",
    "url='https://drive.google.com/file/d/1fKMObDPi3ODKn8n-vj38LY0rf1IVaILe/view?usp=sharing'\n",
    "path='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b51447",
   "metadata": {},
   "source": [
    "### Step 2: Preprocessing text\n",
    "Text preprocessing is a crucial step in performing sentiment analysis, as it helps to clean and normalize the text data, making it easier to analyze. **The preprocessing step involves a series of techniques that help transform raw text data into a form you can use for analysis**. Some common text preprocessing techniques include tokenization, stop word removal, stemming, and lemmatization.\n",
    "\n",
    "- To preprocess our text, we create a function called `preprocess_text` that will go through all the preprocessing steps at once when we feed it a **sentence** (i.e. a review), giving us back a form that we can use for the sentiment analysis. \n",
    "\n",
    "Let us go through the processes with an example movie review I found online: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a1be84c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the movie review\n",
    "sentence = 'One of my favorite movies of all time! It is action packed with great storytelling and a beautiful love story!'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b01e75",
   "metadata": {},
   "source": [
    "#### 2.1 Tokenization\n",
    "The first step of preprocessing involves tokenizing the data. Given a sentence, we want to break it down into individual words or tokens. This allows the sentiment analyzer to analyze individual words.\n",
    "\n",
    "**Note**: Instead of using `word_tokenize` like in DataCamp, I found that `TweetTokenizer` works better at splitting up our data into individual words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4207b89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'of',\n",
       " 'my',\n",
       " 'favorite',\n",
       " 'movies',\n",
       " 'of',\n",
       " 'all',\n",
       " 'time',\n",
       " '!',\n",
       " 'it',\n",
       " 'is',\n",
       " 'action',\n",
       " 'packed',\n",
       " 'with',\n",
       " 'great',\n",
       " 'storytelling',\n",
       " 'and',\n",
       " 'a',\n",
       " 'beautiful',\n",
       " 'love',\n",
       " 'story',\n",
       " '!']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a reference variable for the class \n",
    "word_tokenize = TweetTokenizer() \n",
    "\n",
    "# lowercase the sentence and then tokenize it and store it in the variable tokens \n",
    "tokens = word_tokenize.tokenize(sentence.lower()) \n",
    "\n",
    "# call tokens (we see that the sentence is split up into a list of words and puncuations)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8246e070",
   "metadata": {},
   "source": [
    "#### 2.2 Removing stop words\n",
    "The next step is to remove stop words which involves removing common and irrelevant words that are unlikely to convey much sentiment. Stop words are words that are very common in a language and do not carry much meaning, such as \"and,\" \"the,\" \"of,\" and \"it\".  \n",
    "\n",
    "By removing stop words, the remaining words in the text are more likely to indicate the sentiment being expressed. This can help to improve the accuracy of the sentiment analysis. We can actually see what the stopwords are in the `nltk.corpus` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d2c892d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# a list of the words that are considered stopwords, i.e. words we will remove from our sentence \n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "49189c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'favorite',\n",
       " 'movies',\n",
       " 'time',\n",
       " '!',\n",
       " 'action',\n",
       " 'packed',\n",
       " 'great',\n",
       " 'storytelling',\n",
       " 'beautiful',\n",
       " 'love',\n",
       " 'story',\n",
       " '!']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the code below goes through every word in the variable tokens and check if its a word in the stopwords list above,\n",
    "# if it is then it is ignored, if its not then we store that word in a new list called filtered_tokens\n",
    "filtered_tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "\n",
    "# calling filtered_tokens we see that stopwords such as 'is', 'on', 'the' are removed\n",
    "filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec85445c",
   "metadata": {},
   "source": [
    "#### 2.3 Stemming and Lemmatization\n",
    "Stemming and lemmatization involves reducing words back into their root form. Stemming involves removing the suffixes from words, such as \"ing\" and \"ed\". Lemmatization involves breaking down a word to its root meaning. Example, reducing the word \"better\" to \"good\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ef1d5248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'favorite',\n",
       " 'movie',\n",
       " 'time',\n",
       " '!',\n",
       " 'action',\n",
       " 'packed',\n",
       " 'great',\n",
       " 'storytelling',\n",
       " 'beautiful',\n",
       " 'love',\n",
       " 'story',\n",
       " '!']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create reference variable for the class\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# the code below goes through every word we have in filtered_tokens, lemmatizes it, and then stores it in a list \n",
    "# called lemmatized_tokens\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "\n",
    "# calling the list (in this case not many words have changed, only plurals turned singular, e.g. stunts -> stunt)\n",
    "lemmatized_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0935394a",
   "metadata": {},
   "source": [
    "#### 2.4 Joining tokens back into a string \n",
    "Last step involves joining the remaining tokens back into one sentence or string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "449cfe6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one favorite movie time ! action packed great storytelling beautiful love story !'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the join function, we can join the list by adding a space in between each word\n",
    "processed_text = ' '.join(lemmatized_tokens)\n",
    "\n",
    "# calling it we have\n",
    "processed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d53f69",
   "metadata": {},
   "source": [
    "#### 2.5 Preprocessing our data set\n",
    "We combine all the steps above into a function called `preprocess_text` so that we can preprocess the whole sentence in one go for each movie review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6fbd4481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the preprocess_text function that takes in a sentence and returns the preprocessed form of it \n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # tokenize the text - split data (the sentence) into a list of words and symbols\n",
    "    word_tokenize = TweetTokenizer() \n",
    "    tokens = word_tokenize.tokenize(text.lower())\n",
    "    \n",
    "    # remove stopwords - i.e. words that are commonly used in a sentence that do not help with analysis\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    \n",
    "    # lemmatize the tokens - i.e. reduce words to its most basic form, e.g. rocks -> rock\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    \n",
    "    # join tokens back into a string \n",
    "    processed_text = ' '.join(lemmatized_tokens)\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "96c8638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the preprocessed text in a new column called 'Processed Review'\n",
    "data['Processed Review'] = data['Clean_Review'].apply(preprocess_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3bdbae",
   "metadata": {},
   "source": [
    "### Step 3: NLTK Analyzer\n",
    "\n",
    "#### 3.1 Sentiment Analyzer (VADER)\n",
    "The final step is to feed the sentence into the NLTK sentiment analyzer (VADER) and evaluate it. We will consider the following:\n",
    "* positive reviews have a `sentiment = 1`\n",
    "* neutral reviews have a `sentiment = 0`\n",
    "* negative reviews have a `sentiment = -1`\n",
    "\n",
    "\n",
    "We can continue with the example sentence that we preprocessed above called `processed_text`.\n",
    "\n",
    "**Note**: VADER spits out scores for positive, neutral and negative. The sum of them is equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "22eec7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.307, 'pos': 0.693}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating reference variable \n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Scoring the sentence \n",
    "scores = analyzer.polarity_scores(processed_text)\n",
    "\n",
    "# there is also a score called 'compound' but since we are only interested in 'neg', 'neu', and 'pos', we will \n",
    "# remove 'compound'\n",
    "scores.popitem()\n",
    "\n",
    "# checking the score\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331d9326",
   "metadata": {},
   "source": [
    "For our analysis, we will consider the sentiment of the review based on which score is the highest (different from DataCamp). For example, in the scores above, `'pos': 0.693` is highest, therefore this review is positive and so `sentiment = 1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "558bc6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the highest score \n",
    "highest_score = max(scores, key=scores.get)\n",
    "\n",
    "if highest_score == 'pos': # \n",
    "    sentiment = 1\n",
    "elif highest_score == 'neu':\n",
    "    sentiment = 0\n",
    "else: \n",
    "    sentiment = -1\n",
    "    \n",
    "# call sentiment\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184bd538",
   "metadata": {},
   "source": [
    "#### 3.2 Analyzing our data set\n",
    "Below we combine everything together in one function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9172224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create get_sentiment function that takes in a sentence and scores it on negative, neutral, or positive\n",
    "def get_sentiment(text):\n",
    "    \n",
    "    # Initialize NLTK sentiment analyzer by creating reference variable \n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    # scoring the sentence \n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    scores.popitem() # removing the 'compound' value from the scoring since we don't need it \n",
    "    \n",
    "    highest_score = max(scores, key=scores.get) # check whether positive, neutral or negative has the highest value\n",
    "    \n",
    "    # assign the appropriate sentiment value based on highest_score\n",
    "    if highest_score == 'pos': \n",
    "        sentiment = 1\n",
    "    elif highest_score == 'neu':\n",
    "        sentiment = 0\n",
    "    else: \n",
    "        sentiment = -1\n",
    "        \n",
    "    return sentiment # return the sentiment for the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5aca890d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Reviewer name</th>\n",
       "      <th>Clean_Review_date</th>\n",
       "      <th>Clean_Review</th>\n",
       "      <th>Clean_Comment Count</th>\n",
       "      <th>Like count</th>\n",
       "      <th>genre</th>\n",
       "      <th>Processed Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clue</td>\n",
       "      <td>1985</td>\n",
       "      <td>Branson Reese</td>\n",
       "      <td>1996-10-16</td>\n",
       "      <td>My dad got in so much trouble for showing me t...</td>\n",
       "      <td>6</td>\n",
       "      <td>2,286 likes</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>dad got much trouble showing kid started sayin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beetlejuice</td>\n",
       "      <td>1988</td>\n",
       "      <td>Branson Reese</td>\n",
       "      <td>1999-10-21</td>\n",
       "      <td>Thank GOD Tim Burton made this movie in 1988 a...</td>\n",
       "      <td>12</td>\n",
       "      <td>3,304 likes</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>thank god tim burton made movie 1988 2008 . im...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Being John Malkovich</td>\n",
       "      <td>1999</td>\n",
       "      <td>Than Tibbetts</td>\n",
       "      <td>2010-10-04</td>\n",
       "      <td>Malkovich. Malkovich Malkovich Malkovich, Malk...</td>\n",
       "      <td>6</td>\n",
       "      <td>4,300 likes</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>malkovich . malkovich malkovich malkovich , ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Muppets</td>\n",
       "      <td>2011</td>\n",
       "      <td>Jeff</td>\n",
       "      <td>2012-03-06</td>\n",
       "      <td>It's fine if you don't like this movie, but it...</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>fine like movie , probably mean angry , hate-f...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mysterious Skin</td>\n",
       "      <td>2004</td>\n",
       "      <td>Cole</td>\n",
       "      <td>2012-03-11</td>\n",
       "      <td>This movie is beautiful, captivating, fascinat...</td>\n",
       "      <td>4</td>\n",
       "      <td>6  23 likes</td>\n",
       "      <td>Drama</td>\n",
       "      <td>movie beautiful , captivating , fascinating , ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>Drive</td>\n",
       "      <td>2011</td>\n",
       "      <td>k??rsten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes, I just saw it for the first timeYes, I lo...</td>\n",
       "      <td>9</td>\n",
       "      <td>2,160 likes</td>\n",
       "      <td>Action</td>\n",
       "      <td>yes , saw first timeyes , loved everything ity...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>1999</td>\n",
       "      <td>hunt??r</td>\n",
       "      <td>NaN</td>\n",
       "      <td>if I was next to brad, I would have dropped th...</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama</td>\n",
       "      <td>next brad , would dropped soap</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>The Bling Ring</td>\n",
       "      <td>2013</td>\n",
       "      <td>k??rsten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not a single good shot or outfit in this entir...</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crime</td>\n",
       "      <td>single good shot outfit entire thing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>A Serbian Film</td>\n",
       "      <td>2010</td>\n",
       "      <td>DirkH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OH MY GOD, LOOK AT HOW CONTROVERSIAL I AM!!!!!!</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Horror</td>\n",
       "      <td>oh god , look controversial ! ! !</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>CODA</td>\n",
       "      <td>2021</td>\n",
       "      <td>James (Schaffrillas)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crazy how such a cliche and predictable movie ...</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama</td>\n",
       "      <td>crazy cliche predictable movie could sooooooo ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2837 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                movie_name  Release Year         Reviewer name  \\\n",
       "0                     Clue          1985         Branson Reese   \n",
       "1              Beetlejuice          1988         Branson Reese   \n",
       "2     Being John Malkovich          1999         Than Tibbetts   \n",
       "3              The Muppets          2011                  Jeff   \n",
       "4          Mysterious Skin          2004                  Cole   \n",
       "...                    ...           ...                   ...   \n",
       "2832                 Drive          2011              k??rsten   \n",
       "2833            Fight Club          1999               hunt??r   \n",
       "2834        The Bling Ring          2013              k??rsten   \n",
       "2835        A Serbian Film          2010                 DirkH   \n",
       "2836                  CODA          2021  James (Schaffrillas)   \n",
       "\n",
       "     Clean_Review_date                                       Clean_Review  \\\n",
       "0           1996-10-16  My dad got in so much trouble for showing me t...   \n",
       "1           1999-10-21  Thank GOD Tim Burton made this movie in 1988 a...   \n",
       "2           2010-10-04  Malkovich. Malkovich Malkovich Malkovich, Malk...   \n",
       "3           2012-03-06  It's fine if you don't like this movie, but it...   \n",
       "4           2012-03-11  This movie is beautiful, captivating, fascinat...   \n",
       "...                ...                                                ...   \n",
       "2832               NaN  Yes, I just saw it for the first timeYes, I lo...   \n",
       "2833               NaN  if I was next to brad, I would have dropped th...   \n",
       "2834               NaN  not a single good shot or outfit in this entir...   \n",
       "2835               NaN    OH MY GOD, LOOK AT HOW CONTROVERSIAL I AM!!!!!!   \n",
       "2836               NaN  Crazy how such a cliche and predictable movie ...   \n",
       "\n",
       "     Clean_Comment Count     Like count   genre  \\\n",
       "0                      6    2,286 likes  Comedy   \n",
       "1                     12    3,304 likes  Comedy   \n",
       "2                      6    4,300 likes  Comedy   \n",
       "3                     31            NaN  Comedy   \n",
       "4                      4    6  23 likes   Drama   \n",
       "...                  ...            ...     ...   \n",
       "2832                   9    2,160 likes  Action   \n",
       "2833                  19            NaN   Drama   \n",
       "2834                  30            NaN   Crime   \n",
       "2835                  65            NaN  Horror   \n",
       "2836                  32            NaN   Drama   \n",
       "\n",
       "                                       Processed Review  Sentiment  \n",
       "0     dad got much trouble showing kid started sayin...          0  \n",
       "1     thank god tim burton made movie 1988 2008 . im...          0  \n",
       "2     malkovich . malkovich malkovich malkovich , ma...          0  \n",
       "3     fine like movie , probably mean angry , hate-f...         -1  \n",
       "4     movie beautiful , captivating , fascinating , ...          1  \n",
       "...                                                 ...        ...  \n",
       "2832  yes , saw first timeyes , loved everything ity...          0  \n",
       "2833                     next brad , would dropped soap          0  \n",
       "2834               single good shot outfit entire thing          0  \n",
       "2835                  oh god , look controversial ! ! !          1  \n",
       "2836  crazy cliche predictable movie could sooooooo ...          0  \n",
       "\n",
       "[2837 rows x 10 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the sentiment in a new column called 'Sentiment'\n",
    "data['Sentiment'] = data['Processed Review'].apply(get_sentiment)\n",
    "\n",
    "# lets see what our data looks like now \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0464f97b",
   "metadata": {},
   "source": [
    "### Dropping the Processed Review column and storing the data into a new CSV\n",
    "Since we do not need Processed Review, I can drop it and then save the rest in a new CSV file called `final_sentiment_letterboxd.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4b5da5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column \n",
    "if 'Processed Review' in data.head():\n",
    "    data.drop(['Processed Review'], axis=1, inplace=True)\n",
    "\n",
    "# save as new CSV\n",
    "data.to_csv('final_sentiment_letterboxd_.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6133a1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 381 positive reviews, 2200 neutral reviews and 256 negative reviews\n"
     ]
    }
   ],
   "source": [
    "# How many positive, neutral and negative reviews are there? \n",
    "pos = 0 \n",
    "neu = 0\n",
    "neg = 0\n",
    "\n",
    "for i in range(len(data)):\n",
    "    if data['Sentiment'][i] == 1:\n",
    "        pos += 1\n",
    "    elif data['Sentiment'][i] == 0:\n",
    "        neu += 1\n",
    "    else:\n",
    "        neg += 1\n",
    "\n",
    "print(\"There are\", pos, \"positive reviews,\", neu, \"neutral reviews and\", neg, \"negative reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cdd8c0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Reviewer name</th>\n",
       "      <th>Clean_Review_date</th>\n",
       "      <th>Clean_Review</th>\n",
       "      <th>Clean_Comment Count</th>\n",
       "      <th>Like count</th>\n",
       "      <th>genre</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clue</td>\n",
       "      <td>1985</td>\n",
       "      <td>Branson Reese</td>\n",
       "      <td>1996-10-16</td>\n",
       "      <td>My dad got in so much trouble for showing me t...</td>\n",
       "      <td>6</td>\n",
       "      <td>2,286 likes</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beetlejuice</td>\n",
       "      <td>1988</td>\n",
       "      <td>Branson Reese</td>\n",
       "      <td>1999-10-21</td>\n",
       "      <td>Thank GOD Tim Burton made this movie in 1988 a...</td>\n",
       "      <td>12</td>\n",
       "      <td>3,304 likes</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Being John Malkovich</td>\n",
       "      <td>1999</td>\n",
       "      <td>Than Tibbetts</td>\n",
       "      <td>2010-10-04</td>\n",
       "      <td>Malkovich. Malkovich Malkovich Malkovich, Malk...</td>\n",
       "      <td>6</td>\n",
       "      <td>4,300 likes</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Muppets</td>\n",
       "      <td>2011</td>\n",
       "      <td>Jeff</td>\n",
       "      <td>2012-03-06</td>\n",
       "      <td>It's fine if you don't like this movie, but it...</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mysterious Skin</td>\n",
       "      <td>2004</td>\n",
       "      <td>Cole</td>\n",
       "      <td>2012-03-11</td>\n",
       "      <td>This movie is beautiful, captivating, fascinat...</td>\n",
       "      <td>4</td>\n",
       "      <td>6  23 likes</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>Drive</td>\n",
       "      <td>2011</td>\n",
       "      <td>k??rsten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes, I just saw it for the first timeYes, I lo...</td>\n",
       "      <td>9</td>\n",
       "      <td>2,160 likes</td>\n",
       "      <td>Action</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>1999</td>\n",
       "      <td>hunt??r</td>\n",
       "      <td>NaN</td>\n",
       "      <td>if I was next to brad, I would have dropped th...</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>The Bling Ring</td>\n",
       "      <td>2013</td>\n",
       "      <td>k??rsten</td>\n",
       "      <td>NaN</td>\n",
       "      <td>not a single good shot or outfit in this entir...</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crime</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>A Serbian Film</td>\n",
       "      <td>2010</td>\n",
       "      <td>DirkH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OH MY GOD, LOOK AT HOW CONTROVERSIAL I AM!!!!!!</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Horror</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>CODA</td>\n",
       "      <td>2021</td>\n",
       "      <td>James (Schaffrillas)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Crazy how such a cliche and predictable movie ...</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2837 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                movie_name  Release Year         Reviewer name  \\\n",
       "0                     Clue          1985         Branson Reese   \n",
       "1              Beetlejuice          1988         Branson Reese   \n",
       "2     Being John Malkovich          1999         Than Tibbetts   \n",
       "3              The Muppets          2011                  Jeff   \n",
       "4          Mysterious Skin          2004                  Cole   \n",
       "...                    ...           ...                   ...   \n",
       "2832                 Drive          2011              k??rsten   \n",
       "2833            Fight Club          1999               hunt??r   \n",
       "2834        The Bling Ring          2013              k??rsten   \n",
       "2835        A Serbian Film          2010                 DirkH   \n",
       "2836                  CODA          2021  James (Schaffrillas)   \n",
       "\n",
       "     Clean_Review_date                                       Clean_Review  \\\n",
       "0           1996-10-16  My dad got in so much trouble for showing me t...   \n",
       "1           1999-10-21  Thank GOD Tim Burton made this movie in 1988 a...   \n",
       "2           2010-10-04  Malkovich. Malkovich Malkovich Malkovich, Malk...   \n",
       "3           2012-03-06  It's fine if you don't like this movie, but it...   \n",
       "4           2012-03-11  This movie is beautiful, captivating, fascinat...   \n",
       "...                ...                                                ...   \n",
       "2832               NaN  Yes, I just saw it for the first timeYes, I lo...   \n",
       "2833               NaN  if I was next to brad, I would have dropped th...   \n",
       "2834               NaN  not a single good shot or outfit in this entir...   \n",
       "2835               NaN    OH MY GOD, LOOK AT HOW CONTROVERSIAL I AM!!!!!!   \n",
       "2836               NaN  Crazy how such a cliche and predictable movie ...   \n",
       "\n",
       "     Clean_Comment Count     Like count   genre  Sentiment  \n",
       "0                      6    2,286 likes  Comedy          0  \n",
       "1                     12    3,304 likes  Comedy          0  \n",
       "2                      6    4,300 likes  Comedy          0  \n",
       "3                     31            NaN  Comedy         -1  \n",
       "4                      4    6  23 likes   Drama          1  \n",
       "...                  ...            ...     ...        ...  \n",
       "2832                   9    2,160 likes  Action          0  \n",
       "2833                  19            NaN   Drama          0  \n",
       "2834                  30            NaN   Crime          0  \n",
       "2835                  65            NaN  Horror          1  \n",
       "2836                  32            NaN   Drama          0  \n",
       "\n",
       "[2837 rows x 9 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376fb2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2cf477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6710d10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
